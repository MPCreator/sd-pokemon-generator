{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a721156",
   "metadata": {},
   "source": [
    "# Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32496b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robdewit/Documents/text2image/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import torch\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from diffusers import DDIMScheduler, DiffusionPipeline, StableDiffusionPipeline\n",
    "# from lora_diffusion import inject_trainable_lora, extract_lora_ups_down\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b1d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_project_root() -> Optional[Path]:\n",
    "    current = Path(\".\").resolve()\n",
    "    \n",
    "    while True:\n",
    "        if (current / \".git\").exists():\n",
    "            return current\n",
    "        \n",
    "        if current.parent == current:\n",
    "            print(\"WARNING: No .git dir found\")\n",
    "            return current\n",
    "              \n",
    "        current = current.parent\n",
    "        \n",
    "\n",
    "PROJECT_ROOT = find_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743d57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "\n",
    "BASE_MODEL = 'runwayml/stable-diffusion-v1-5'\n",
    "INPUT_DATA = 'data/external/pokemon'\n",
    "POKEMON_STATS = 'data/external/pokemon_stats.csv'\n",
    "TRAIN_DATA = 'data/processed/pokemon'\n",
    "TARGET_POKEMON_TYPE = \"water\"\n",
    "TARGET_POKEMON_GENERATION = 1\n",
    "MODEL_DIRECTORY = 'models'\n",
    "LORA_NAME = f\"type-{TARGET_POKEMON_TYPE}-generation-{TARGET_POKEMON_GENERATION}\"\n",
    "LORA_PATH = f\"{MODEL_DIRECTORY}/{LORA_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb47d96",
   "metadata": {},
   "source": [
    "# Get subset of relevant Pok√©mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44bdda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pokedex_number</th>\n",
       "      <th>name</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Squirtle</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Wartortle</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Blastoise</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>Psyduck</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>Golduck</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pokedex_number       name  type1 type2  generation\n",
       "6                7   Squirtle  water   NaN           1\n",
       "7                8  Wartortle  water   NaN           1\n",
       "8                9  Blastoise  water   NaN           1\n",
       "53              54    Psyduck  water   NaN           1\n",
       "54              55    Golduck  water   NaN           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon = pd.read_csv(PROJECT_ROOT / POKEMON_STATS)\n",
    "pokemon = pokemon[[\"pokedex_number\", \"name\", \"type1\", \"type2\", \"generation\"]]\n",
    "\n",
    "pokemon.head()\n",
    "\n",
    "if not TARGET_POKEMON_TYPE.lower() in ['all', 'none', '']:\n",
    "    subset_1 = pokemon.loc[pokemon['type1'] == TARGET_POKEMON_TYPE]\n",
    "    subset_2 = pokemon.loc[pokemon['type2'] == TARGET_POKEMON_TYPE]\n",
    "    \n",
    "    subset = pd.concat([subset_1, subset_2]).sort_values('pokedex_number')\n",
    "    \n",
    "if not TARGET_POKEMON_GENERATION in [-1, 0]:\n",
    "    subset = subset.loc[subset['generation'] == TARGET_POKEMON_GENERATION]\n",
    "    \n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ffd73",
   "metadata": {},
   "source": [
    "# Resize training images to desired resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da154b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory and clear if it already exists\n",
    "if not os.path.exists(PROJECT_ROOT / TRAIN_DATA):\n",
    "    os.mkdir(PROJECT_ROOT / TRAIN_DATA)\n",
    "else:\n",
    "    shutil.rmtree(PROJECT_ROOT / TRAIN_DATA)\n",
    "    os.mkdir(PROJECT_ROOT / TRAIN_DATA)\n",
    "          \n",
    "# Resize training images and save to processed directory\n",
    "for image_name in os.listdir(PROJECT_ROOT/INPUT_DATA):\n",
    "    \n",
    "    # Only keep sprites of our defined subset (e.g. water type generation 1)\n",
    "    pokedex_number = int(image_name.split('.')[0])\n",
    "    \n",
    "    if pokedex_number in list(subset['pokedex_number']):\n",
    "        pokemon_sprite = Image.open(PROJECT_ROOT/ INPUT_DATA / image_name)\n",
    "        pokemon_sprite_resized = pokemon_sprite.resize((512, 512))\n",
    "\n",
    "        # Add leading zeroes\n",
    "        while len(image_name) < 8:\n",
    "            image_name = \"0\" + image_name\n",
    "\n",
    "        pokemon_sprite_resized.save(PROJECT_ROOT / TRAIN_DATA / image_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4d4ff",
   "metadata": {},
   "source": [
    "# Train LoRA  (bash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb16dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robdewit/Documents/text2image/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:231: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ü§ó Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "04/12/2023 11:21:34 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: mps\n",
      "Mixed precision type: no\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'clip_sample_range', 'variance_type', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'projection_class_embeddings_input_dim', 'only_cross_attention', 'conv_in_kernel', 'use_linear_projection', 'num_class_embeds', 'dual_cross_attention', 'upcast_attention', 'timestep_post_act', 'time_cond_proj_dim', 'conv_out_kernel', 'resnet_time_scale_shift', 'time_embedding_type', 'mid_block_type', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
      "wandb: Currently logged in as: robdewit. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.14.2\n",
      "wandb: Run data is saved locally in /Users/robdewit/Documents/text2image/notebooks/wandb/run-20230412_112139-6ww56m98\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run easy-valley-5\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/robdewit/dreambooth-lora\n",
      "wandb: üöÄ View run at https://wandb.ai/robdewit/dreambooth-lora/runs/6ww56m98\n",
      "04/12/2023 11:21:40 - INFO - __main__ - ***** Running training *****\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Num examples = 32\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Num batches each epoch = 32\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Num Epochs = 16\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "04/12/2023 11:21:40 - INFO - __main__ -   Total optimization steps = 500\n",
      "Steps:   6%|‚ñã         | 32/500 [00:55<12:58,  1.66s/it, loss=0.0887, lr=0.0001]04/12/2023 11:22:35 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: a drawing of a pokemon.\n",
      "\n",
      "Fetching 15 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 20915.74it/s]\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "/Users/robdewit/Documents/text2image/.venv/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "{'thresholding', 'lower_order_final', 'sample_max_value', 'solver_order', 'algorithm_type', 'dynamic_thresholding_ratio', 'solver_type'} was not found in config. Values will be initialized to default values.\n",
      "Steps:  20%|‚ñà‚ñà        | 100/500 [04:19<11:10,  1.68s/it, loss=0.0243, lr=0.0001]04/12/2023 11:25:59 - INFO - accelerate.accelerator - Saving current state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-100\n",
      "04/12/2023 11:25:59 - INFO - accelerate.checkpointing - Model weights saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-100/pytorch_model.bin\n",
      "04/12/2023 11:25:59 - INFO - accelerate.checkpointing - Optimizer state saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-100/optimizer.bin\n",
      "04/12/2023 11:25:59 - INFO - accelerate.checkpointing - Random states saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-100/random_states_0.pkl\n",
      "04/12/2023 11:25:59 - INFO - accelerate.checkpointing - Saving the state of AttnProcsLayers to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-100/custom_checkpoint_0.pkl\n",
      "04/12/2023 11:26:00 - INFO - __main__ - Saved state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-100\n",
      "Steps:  40%|‚ñà‚ñà‚ñà‚ñà      | 200/500 [07:07<08:26,  1.69s/it, loss=0.0178, lr=0.0001]04/12/2023 11:28:47 - INFO - accelerate.accelerator - Saving current state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-200\n",
      "04/12/2023 11:28:47 - INFO - accelerate.checkpointing - Model weights saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-200/pytorch_model.bin\n",
      "04/12/2023 11:28:47 - INFO - accelerate.checkpointing - Optimizer state saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-200/optimizer.bin\n",
      "04/12/2023 11:28:47 - INFO - accelerate.checkpointing - Random states saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-200/random_states_0.pkl\n",
      "04/12/2023 11:28:47 - INFO - accelerate.checkpointing - Saving the state of AttnProcsLayers to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-200/custom_checkpoint_0.pkl\n",
      "04/12/2023 11:28:47 - INFO - __main__ - Saved state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-200\n",
      "Steps:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 300/500 [09:54<05:33,  1.67s/it, loss=0.0502, lr=0.0001]04/12/2023 11:31:34 - INFO - accelerate.accelerator - Saving current state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-300\n",
      "04/12/2023 11:31:34 - INFO - accelerate.checkpointing - Model weights saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-300/pytorch_model.bin\n",
      "04/12/2023 11:31:34 - INFO - accelerate.checkpointing - Optimizer state saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-300/optimizer.bin\n",
      "04/12/2023 11:31:34 - INFO - accelerate.checkpointing - Random states saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-300/random_states_0.pkl\n",
      "04/12/2023 11:31:34 - INFO - accelerate.checkpointing - Saving the state of AttnProcsLayers to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-300/custom_checkpoint_0.pkl\n",
      "04/12/2023 11:31:34 - INFO - __main__ - Saved state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-300\n",
      "Steps:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 400/500 [12:42<02:46,  1.67s/it, loss=0.0733, lr=0.0001]04/12/2023 11:34:22 - INFO - accelerate.accelerator - Saving current state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-400\n",
      "04/12/2023 11:34:22 - INFO - accelerate.checkpointing - Model weights saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-400/pytorch_model.bin\n",
      "04/12/2023 11:34:22 - INFO - accelerate.checkpointing - Optimizer state saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-400/optimizer.bin\n",
      "04/12/2023 11:34:22 - INFO - accelerate.checkpointing - Random states saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-400/random_states_0.pkl\n",
      "04/12/2023 11:34:22 - INFO - accelerate.checkpointing - Saving the state of AttnProcsLayers to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-400/custom_checkpoint_0.pkl\n",
      "04/12/2023 11:34:22 - INFO - __main__ - Saved state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-400\n",
      "Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [15:29<00:00,  1.68s/it, loss=0.0393, lr=0.0001]04/12/2023 11:37:09 - INFO - accelerate.accelerator - Saving current state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-500\n",
      "04/12/2023 11:37:09 - INFO - accelerate.checkpointing - Model weights saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/12/2023 11:37:10 - INFO - accelerate.checkpointing - Optimizer state saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-500/optimizer.bin\n",
      "04/12/2023 11:37:10 - INFO - accelerate.checkpointing - Random states saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-500/random_states_0.pkl\n",
      "04/12/2023 11:37:10 - INFO - accelerate.checkpointing - Saving the state of AttnProcsLayers to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-500/custom_checkpoint_0.pkl\n",
      "04/12/2023 11:37:10 - INFO - __main__ - Saved state to /Users/robdewit/Documents/text2image/models/type-water-generation-1/checkpoint-500\n",
      "Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [15:29<00:00,  1.68s/it, loss=0.0907, lr=0.0001]Model weights saved in /Users/robdewit/Documents/text2image/models/type-water-generation-1/pytorch_lora_weights.bin\n",
      "\n",
      "Fetching 15 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 130528.13it/s]\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'projection_class_embeddings_input_dim', 'only_cross_attention', 'conv_in_kernel', 'use_linear_projection', 'num_class_embeds', 'dual_cross_attention', 'upcast_attention', 'timestep_post_act', 'time_cond_proj_dim', 'conv_out_kernel', 'resnet_time_scale_shift', 'time_embedding_type', 'mid_block_type', 'class_embed_type'} was not found in config. Values will be initialized to default values.\n",
      "{'thresholding', 'lower_order_final', 'sample_max_value', 'solver_order', 'algorithm_type', 'dynamic_thresholding_ratio', 'solver_type'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|‚ñç         | 1/25 [00:04<01:48,  4.52s/it]\u001b[A\n",
      "  8%|‚ñä         | 2/25 [00:05<00:54,  2.35s/it]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 3/25 [00:06<00:36,  1.66s/it]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 4/25 [00:07<00:27,  1.33s/it]\u001b[A\n",
      " 20%|‚ñà‚ñà        | 5/25 [00:07<00:23,  1.15s/it]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 6/25 [00:08<00:19,  1.04s/it]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 7/25 [00:09<00:17,  1.03it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:10<00:15,  1.07it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:11<00:14,  1.11it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:12<00:13,  1.14it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:12<00:12,  1.16it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:13<00:11,  1.18it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:14<00:10,  1.19it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:15<00:09,  1.19it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:16<00:08,  1.20it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:16<00:07,  1.19it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:17<00:06,  1.20it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:18<00:05,  1.20it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:19<00:04,  1.20it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:20<00:04,  1.21it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:21<00:03,  1.21it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:21<00:02,  1.21it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:22<00:01,  1.21it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:23<00:00,  1.21it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:24<00:00,  1.02it/s]\u001b[A\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|‚ñç         | 1/25 [00:00<00:19,  1.21it/s]\u001b[A\n",
      "  8%|‚ñä         | 2/25 [00:01<00:18,  1.21it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 3/25 [00:02<00:18,  1.21it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 4/25 [00:03<00:17,  1.21it/s]\u001b[A\n",
      " 20%|‚ñà‚ñà        | 5/25 [00:04<00:16,  1.21it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 6/25 [00:04<00:15,  1.21it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 7/25 [00:05<00:14,  1.21it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:06<00:14,  1.21it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:07<00:13,  1.21it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:08<00:12,  1.21it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:09<00:11,  1.21it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:09<00:10,  1.21it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:10<00:09,  1.21it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:11<00:09,  1.21it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:12<00:08,  1.21it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:13<00:07,  1.21it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:14<00:06,  1.21it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:14<00:05,  1.21it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:15<00:04,  1.21it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:16<00:04,  1.21it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:17<00:03,  1.21it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:02,  1.21it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:18<00:01,  1.21it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:00,  1.21it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  1.21it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|‚ñç         | 1/25 [00:00<00:19,  1.21it/s]\u001b[A\n",
      "  8%|‚ñä         | 2/25 [00:01<00:18,  1.21it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 3/25 [00:02<00:18,  1.21it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 4/25 [00:03<00:17,  1.21it/s]\u001b[A\n",
      " 20%|‚ñà‚ñà        | 5/25 [00:04<00:16,  1.21it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 6/25 [00:04<00:15,  1.21it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 7/25 [00:05<00:14,  1.21it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:06<00:14,  1.21it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:07<00:13,  1.21it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:08<00:12,  1.21it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:09<00:11,  1.21it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:09<00:10,  1.21it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:10<00:09,  1.21it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:11<00:09,  1.21it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:12<00:08,  1.21it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:13<00:07,  1.21it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:14<00:06,  1.21it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:14<00:05,  1.21it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:15<00:04,  1.21it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:16<00:04,  1.21it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:17<00:03,  1.21it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:02,  1.21it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:18<00:01,  1.21it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:00,  1.21it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  1.21it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|‚ñç         | 1/25 [00:00<00:19,  1.21it/s]\u001b[A\n",
      "  8%|‚ñä         | 2/25 [00:01<00:18,  1.21it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 3/25 [00:02<00:18,  1.21it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 4/25 [00:03<00:17,  1.21it/s]\u001b[A\n",
      " 20%|‚ñà‚ñà        | 5/25 [00:04<00:16,  1.21it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 6/25 [00:04<00:15,  1.21it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 7/25 [00:05<00:14,  1.21it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:06<00:14,  1.21it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:07<00:13,  1.21it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:08<00:12,  1.21it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:09<00:11,  1.21it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:09<00:10,  1.21it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:10<00:09,  1.21it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:11<00:09,  1.21it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:12<00:08,  1.21it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:13<00:07,  1.21it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:14<00:06,  1.21it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:14<00:05,  1.21it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:15<00:04,  1.21it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:16<00:04,  1.21it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:17<00:03,  1.21it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:18<00:02,  1.21it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:18<00:01,  1.21it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:19<00:00,  1.21it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:20<00:00,  1.21it/s]\u001b[A\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: / 2.773 MB of 2.773 MB uploaded (0.000 MB deduped)\n",
      "wandb: Run history:\n",
      "wandb: loss ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ\n",
      "wandb:   lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb: loss 0.09074\n",
      "wandb:   lr 0.0001\n",
      "wandb: \n",
      "wandb: üöÄ View run easy-valley-5 at: https://wandb.ai/robdewit/dreambooth-lora/runs/6ww56m98\n",
      "wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230412_112139-6ww56m98/logs\n",
      "/Users/robdewit/Documents/text2image/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2087: UserWarning: Run (6ww56m98) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [17:18<00:00,  2.08s/it, loss=0.0907, lr=0.0001]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$PROJECT_ROOT\" \"$BASE_MODEL\" \"$TRAIN_DATA\" \"$LORA_PATH\"\n",
    "\n",
    "export PROJECT_ROOT=$1\n",
    "export BASE_MODEL=$2\n",
    "export TRAIN_DATA=$3\n",
    "export LORA_PATH=$4\n",
    "\n",
    "# NEED TO RUN THESE ONCE\n",
    "# git clone --depth 1 --branch v0.14.0 https://github.com/huggingface/diffusers.git $PROJECT_ROOT/diffusers\n",
    "# pip3.10 install -r \"${PROJECT_ROOT}/diffusers/examples/dreambooth/requirements.txt\"\n",
    "# accelerate config default\n",
    "\n",
    "# --mps needed for Mac M1+\n",
    "accelerate launch --mps \"${PROJECT_ROOT}/diffusers/examples/dreambooth/train_dreambooth_lora.py\" \\\n",
    "  --pretrained_model_name_or_path=$BASE_MODEL  \\\n",
    "  --instance_data_dir=$PROJECT_ROOT/$TRAIN_DATA \\\n",
    "  --output_dir=$PROJECT_ROOT/$LORA_PATH \\\n",
    "  --instance_prompt=\"Digital art of rcdw pokemon\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --checkpointing_steps=100 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=500 \\\n",
    "  --validation_prompt=\"Digital art of rcdw pokemon\" \\\n",
    "  --validation_epochs=50 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --seed=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerate launch --mps \"diffusers/examples/dreambooth/train_dreambooth_lora.py\" \\\n",
    "#   --pretrained_model_name_or_path='runwayml/stable-diffusion-v1-5' \\\n",
    "#   --instance_data_dir='data/processed/pokemon' \\\n",
    "#   --output_dir='models/test1' \\\n",
    "#   --instance_prompt=\"a drawing of a pokemon\" \\\n",
    "#   --resolution=512 \\\n",
    "#   --train_batch_size=1 \\\n",
    "#   --gradient_accumulation_steps=1 \\\n",
    "#   --checkpointing_steps=100 \\\n",
    "#   --learning_rate=1e-4 \\\n",
    "#   --lr_scheduler=\"constant\" \\\n",
    "#   --lr_warmup_steps=0 \\\n",
    "#   --max_train_steps=300 \\\n",
    "#   --validation_prompt=\"a drawing of a pokemon\" \\\n",
    "#   --validation_epochs=50 \\\n",
    "#   --seed=\"0\" \\\n",
    "#   --report_to=\"wandb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aedcecb",
   "metadata": {},
   "source": [
    "# Set up SD pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dce4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0826968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LoRA on top of base model weights\n",
    "pipeline.unet.load_attn_procs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These settings work for Apple M1/M2 silicon\n",
    "# Docs for configuring to your hardware: https://huggingface.co/docs/diffusers/optimization/fp16\n",
    "pipeline.to(\"mps\")\n",
    "\n",
    "# Recommended if your computer has < 64 GB of RAM\n",
    "pipeline.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d961ef0",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4159f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(1024)\n",
    "prompt = \"a grass animal in the style of Ken Sugimori\"\n",
    "\n",
    "_ = pipeline(prompt, num_inference_steps=1) # Needed: https://github.com/huggingface/diffusers/issues/372\n",
    "image = pipeline(prompt, num_inference_steps=30, generator=generator).images[0]\n",
    "\n",
    "# TODO: https://huggingface.co/docs/diffusers/using-diffusers/reusing_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgplot = plt.imshow(images[0])\n",
    "# plt.show(image)\n",
    "# # image.save(f\"sd-output.png\")\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac7211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
